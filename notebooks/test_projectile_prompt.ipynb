{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c261f509-0429-4e06-9bdb-fe797f853065",
   "metadata": {},
   "source": [
    "### let GPT propose a symbolic law from sampled projectile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c490fe2-6632-4cbe-80a1-8277f58ca3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# cd llm-physics-discovery/\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from src.simulate import projectile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4841e60b-c057-42c9-8b22-4291cd9ef15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded? True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "print(\"Key loaded?\", os.getenv(\"OPENAI_API_KEY\") is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d5c58de-aec5-4c73-9477-18dc657b5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "t, y, meta = projectile(v0 = 20.0, theta_deg = 45.0, g = 9.81, noise = 0.05, num_points = 200,  seed  = 123)\n",
    "# generate ~10 to 12 points \n",
    "idx = np.linspace(0, len(t)-1, 12, dtype=int)\n",
    "t_sample, y_sample = t[idx], y[idx]\n",
    "t_list, y_list = t_sample.round(4).tolist(), y_sample.round(4).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f518c0f5-d05e-43c5-9b4f-4e369b37275d",
   "metadata": {},
   "source": [
    "### Why I only sample 10–12 points\n",
    "\n",
    "Although the simulation generated 200 data points, I don’t feed all of them into the LLM.  \n",
    "Instead, I provide a smaller, representative sample (about 10–12 points). This choice is important for several reasons:\n",
    "\n",
    "1. **Token efficiency:** Large prompts with hundreds of numbers waste tokens and clutter the input \n",
    "2. **Noise robustness:** Too many noisy points can mislead the LLM; a smaller sample highlights the overall trend (the parabola) \n",
    "3. **Scientific analogy:** Just like a physicist in a lab only needs a handful of measurements to guess a law, the LLM doesn’t need every point\n",
    "4. **Readability:** For documentation and presentation (Medium article), showing 10–12 points keeps the prompt clear and easy to follow \n",
    "\n",
    "With ~10–12 points evenly spaced across the trajectory, GPT sees enough structure to propose the underlying law (`y = A*t - B*t**2`) without being distracted by noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68049363-0e7a-4835-b32c-ec3108395026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a scientist.\n",
      "Given these (t, y) measurements of a projectile’s motion, propose a compact analytic formula y(t).\n",
      "\n",
      "Rules:\n",
      "- Use SymPy/Python syntax (sin, cos, exp, *, **).\n",
      "- Use symbols for constants (A, B, g, v0, etc) — do not hardcode numeric constants.\n",
      "- Keep the expression short.\n",
      "- Return only the formula.\n",
      "\n",
      "t: [0.0, 0.2608, 0.5216, 0.7824, 1.0432, 1.304, 1.5648, 1.8255, 2.0863, 2.3471, 2.6079, 2.8832]\n",
      "y: [-0.1518, 3.3067, 6.1739, 7.9882, 9.5613, 10.2902, 10.2506, 9.4823, 8.2178, 6.0526, 3.4459, -0.2545]\n"
     ]
    }
   ],
   "source": [
    "# build the GPT prompt\n",
    "prompt = f\"\"\"\n",
    "You are a scientist.\n",
    "Given these (t, y) measurements of a projectile’s motion, propose a compact analytic formula y(t).\n",
    "\n",
    "Rules:\n",
    "- Use SymPy/Python syntax (sin, cos, exp, *, **).\n",
    "- Use symbols for constants (A, B, g, v0, etc) — do not hardcode numeric constants.\n",
    "- Keep the expression short.\n",
    "- Return only the formula.\n",
    "\n",
    "t: {t_list}\n",
    "y: {y_list}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5479c007-fd73-49a6-952b-24ce32a65309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT guess: \n",
      " ```python\n",
      "from sympy import symbols, sin, cos\n",
      "\n",
      "t, A, B, g, v0, h0 = symbols('t A B g v0 h0')\n",
      "y = h0 + v0 * t - (1/2) * g * t**2 + A * sin(B * t)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# call the model\n",
    "client = OpenAI() # initialize the client\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "formula = response.choices[0].message.content\n",
    "print(\"GPT guess: \\n\", formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49019a5f-8c61-4fde-ac7d-2b54fe11fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT raw:\n",
      " y = h0 + v0 * t - (1/2) * g * t**2 + A * sin(B * t) \n",
      "\n",
      "Parsed formula:\n",
      " y = h0 + v0 * t - (1/2) * g * t**2 + A * sin(B * t)\n"
     ]
    }
   ],
   "source": [
    "def clean_formula(text):\n",
    "    # remove triple-backtick code fences and language tags\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.strip(\"`\")\n",
    "        # after stripping fences, split off the first line if it's a language tag (e.g., 'python' as shown in the cell above)\n",
    "        lines = text.splitlines()\n",
    "        if lines and lines[0].strip().lower() in {\"python\",\"py\"}:\n",
    "            text = \"\\n\".join(lines[1:])\n",
    "    # keep only the line with the expression if user added imports/variables\n",
    "    # take the last non-empty line as the formula (common pattern)\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    return lines[-1] if lines else text\n",
    "\n",
    "formula = clean_formula(formula)\n",
    "print(\"GPT raw:\\n\", formula, \"\\n\")\n",
    "print(\"Parsed formula:\\n\", formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3c04e25-e4c5-4e93-973e-2a9ad1dcdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"responses\", exist_ok=True)\n",
    "\n",
    "with open(\"responses/projectile_formula.txt\", \"w\") as f:\n",
    "    f.write(formula + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c9ef5-6ef6-4a90-8844-922b0d8e2278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
